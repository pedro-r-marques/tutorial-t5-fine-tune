{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "so-quality-train.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OmDlLEeTrauX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21c77b749c7c45019ddca6aceb4db9cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5b05f721b3f2414a89e1c63642824d6a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3b95c148a3f54821b2434a9bdcf74b0e",
              "IPY_MODEL_6e66cda3a636467fa6c0ed1adb0ca2b7",
              "IPY_MODEL_1bfb752f9e5643acaccd53b2e68ac01e"
            ]
          }
        },
        "5b05f721b3f2414a89e1c63642824d6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b95c148a3f54821b2434a9bdcf74b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a672d4885ab4ca690a532867420e15a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27b65160800c4ae2aa879b818383a92a"
          }
        },
        "6e66cda3a636467fa6c0ed1adb0ca2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_05ec5fee457d4d599ad6688f3381f9ba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 892146080,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 892146080,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_479f382b3c734d5ea0133b89c9402902"
          }
        },
        "1bfb752f9e5643acaccd53b2e68ac01e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_75b8ef19644748bc93505d6933f4495b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 851M/851M [00:22&lt;00:00, 36.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5f649486cb34bd7885485c95438a9a1"
          }
        },
        "1a672d4885ab4ca690a532867420e15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27b65160800c4ae2aa879b818383a92a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05ec5fee457d4d599ad6688f3381f9ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "479f382b3c734d5ea0133b89c9402902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75b8ef19644748bc93505d6933f4495b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5f649486cb34bd7885485c95438a9a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x019Rvd0I7rM"
      },
      "source": [
        "\"\"\"\n",
        "Google cloud variables.\n",
        "\"\"\"\n",
        "GCLOUD_PROJECT=<GOOGLE_CLOUD_PROJECT>\n",
        "GCS_BUCKET=<CLOUD_STORAGE_BUCKET>\n",
        "GCS_MODEL_DIR='so-quality/t5-model/01'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmDlLEeTrauX"
      },
      "source": [
        "## environment setup\n",
        "\n",
        "- authentication for GCS accesss\n",
        "- install packages\n",
        "- tf distribution strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6qrynPGEid0",
        "outputId": "3dd657bc-282f-4083-bdd5-9115a7c3b801"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "!gcloud config set project $GCLOUD_PROJECT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtD_iumFJKIo",
        "outputId": "ae495fbb-b059-4cdf-8ee7-6cf0a69871dc"
      },
      "source": [
        "%pip install transformers==4.11.3\n",
        "%pip install sentencepiece\n",
        "%pip install -q -U tf-models-official"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.11.3 in /usr/local/lib/python3.7/dist-packages (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3) (0.0.46)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3) (0.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3) (4.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3) (21.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3) (0.0.19)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3) (3.3.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers==4.11.3) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.11.3) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.11.3) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.3) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.3) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.3) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.3) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.3) (1.0.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvlUbdGCJP03",
        "outputId": "60c86038-46c4-45de-911c-ec210617e0ec"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from official.nlp import optimization\n",
        "\n",
        "if os.environ.get('COLAB_TPU_ADDR'):\n",
        "  cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "  tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "  tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "  strategy = tf.distribute.TPUStrategy(cluster_resolver)\n",
        "  print('Using TPU')\n",
        "elif tf.config.list_physical_devices('GPU'):\n",
        "  strategy = tf.distribute.MirroredStrategy()\n",
        "  print('Using GPU')\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy()\n",
        "  print('Running on CPU is not recommended.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.96.127.74:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.96.127.74:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyM6S2thrrAq"
      },
      "source": [
        "## dataset\n",
        "\n",
        "With the TFRecord format the dataset can be read directly in the TPU nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLQF_FLdJZlt"
      },
      "source": [
        "def tf_record_decoder(encoded):\n",
        "    features = {\n",
        "        \"input_ids\": tf.io.FixedLenFeature([512], tf.int64),\n",
        "        \"attention_mask\": tf.io.FixedLenFeature([512], tf.int64),\n",
        "        \"labels\": tf.io.FixedLenFeature([2], tf.int64),\n",
        "        \"decoder_attention_mask\": tf.io.FixedLenFeature([2], tf.int64),\n",
        "        \"class\": tf.io.FixedLenFeature([1], tf.int64),\n",
        "    }\n",
        "    tf_record = tf.io.parse_single_example(encoded, features)\n",
        "    return tf_record\n",
        "\n",
        "def dataset_prepare(dataset, batch_size=32, training=False):\n",
        "    dataset = dataset.map(tf_record_decoder)\n",
        "    dataset = dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "    if training:\n",
        "        dataset = dataset.shuffle(1*1024)\n",
        "\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmv1k6vuJTN-"
      },
      "source": [
        "ds_tr_train = tf.data.TFRecordDataset(f'gs://{GCS_BUCKET}/so-quality/dataset_t5_train.tfrecord')\n",
        "ds_tr_valid = tf.data.TFRecordDataset(f'gs://{GCS_BUCKET}/so-quality/dataset_t5_valid.tfrecord')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYDnYMFVJbzo"
      },
      "source": [
        "with strategy.scope():\n",
        "    ds_train = dataset_prepare(ds_tr_train, training=True)\n",
        "    ds_valid = dataset_prepare(ds_tr_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TwHptV3r5MK"
      },
      "source": [
        "## Import pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "21c77b749c7c45019ddca6aceb4db9cc",
            "5b05f721b3f2414a89e1c63642824d6a",
            "3b95c148a3f54821b2434a9bdcf74b0e",
            "6e66cda3a636467fa6c0ed1adb0ca2b7",
            "1bfb752f9e5643acaccd53b2e68ac01e",
            "1a672d4885ab4ca690a532867420e15a",
            "27b65160800c4ae2aa879b818383a92a",
            "05ec5fee457d4d599ad6688f3381f9ba",
            "479f382b3c734d5ea0133b89c9402902",
            "75b8ef19644748bc93505d6933f4495b",
            "b5f649486cb34bd7885485c95438a9a1"
          ]
        },
        "id": "X7lgPrgIJhUA",
        "outputId": "087f30d9-4356-4c1d-e99e-ab68e8f57b10"
      },
      "source": [
        "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
        "\n",
        "with strategy.scope():\n",
        "    tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "    model = TFT5ForConditionalGeneration.from_pretrained('t5-base')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to acquire lock 140161378671824 on /root/.cache/huggingface/transformers/748a176e9d151dcad63a27974db8b8f665f286954cfbb77008ca42163419ff66.6a323429db2b09562cffdb9bc72d09d08bccbca1d832434b183b867864c30526.h5.lock\n",
            "DEBUG:filelock:Lock 140161378671824 acquired on /root/.cache/huggingface/transformers/748a176e9d151dcad63a27974db8b8f665f286954cfbb77008ca42163419ff66.6a323429db2b09562cffdb9bc72d09d08bccbca1d832434b183b867864c30526.h5.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21c77b749c7c45019ddca6aceb4db9cc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/851M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:filelock:Attempting to release lock 140161378671824 on /root/.cache/huggingface/transformers/748a176e9d151dcad63a27974db8b8f665f286954cfbb77008ca42163419ff66.6a323429db2b09562cffdb9bc72d09d08bccbca1d832434b183b867864c30526.h5.lock\n",
            "DEBUG:filelock:Lock 140161378671824 released on /root/.cache/huggingface/transformers/748a176e9d151dcad63a27974db8b8f665f286954cfbb77008ca42163419ff66.6a323429db2b09562cffdb9bc72d09d08bccbca1d832434b183b867864c30526.h5.lock\n",
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwl5VxNxr_0k"
      },
      "source": [
        "### Workaround for a bug in {train,test}_step\n",
        "\n",
        "There was an issue with using metrics with the Model train API which was fixed in https://github.com/huggingface/transformers/pull/14009\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HpGW3_YK_1-"
      },
      "source": [
        "from tensorflow.python.keras.engine import data_adapter\n",
        "\n",
        "def train_step(self, data):\n",
        "    \"\"\"\n",
        "    A modification of Keras's default train_step that cleans up the printed metrics when we use a dummy loss.\n",
        "    \"\"\"\n",
        "    # These are the only transformations `Model.fit` applies to user-input\n",
        "    # data when a `tf.data.Dataset` is provided.\n",
        "    data = data_adapter.expand_1d(data)\n",
        "    x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)\n",
        "    # These next two lines differ from the base method - they avoid issues when the labels are in\n",
        "    # the input dict (and loss is computed internally)\n",
        "    if y is None and \"labels\" in x:\n",
        "        y = x[\"labels\"]  # Stops confusion with metric computations\n",
        "    # Run forward pass.\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = self(x, training=True)\n",
        "        loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)\n",
        "    # Run backwards pass.\n",
        "    self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n",
        "    self.compiled_metrics.update_state(y, y_pred['logits'], sample_weight)\n",
        "    # Collect metrics to return\n",
        "    return_metrics = {}\n",
        "    for metric in self.metrics:\n",
        "        result = metric.result()\n",
        "        if isinstance(result, dict):\n",
        "            return_metrics.update(result)\n",
        "        else:\n",
        "            return_metrics[metric.name] = result\n",
        "    # These next two lines are also not in the base method - they correct the displayed metrics\n",
        "    # when we're using a dummy loss, to avoid a bogus \"loss_loss\" value being shown.\n",
        "    if \"loss\" in return_metrics and \"loss_loss\" in return_metrics:\n",
        "        del return_metrics[\"loss_loss\"]\n",
        "    return return_metrics\n",
        "\n",
        "def test_step(self, data):\n",
        "    \"\"\"\n",
        "    A modification of Keras's default test_step that cleans up the printed metrics when we use a dummy loss.\n",
        "    \"\"\"\n",
        "    data = data_adapter.expand_1d(data)\n",
        "    x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)\n",
        "    # These next two lines differ from the base method - they avoid issues when the labels are in\n",
        "    # the input dict (and loss is computed internally)\n",
        "    if y is None and \"labels\" in x:\n",
        "        y = x[\"labels\"]  # Stops confusion with metric computations\n",
        "    y_pred = self(x, training=False)\n",
        "    if not self.loss:\n",
        "        self.loss_tracker.update_state(y_pred.loss)\n",
        "        return_metrics = {\"loss\": self.loss_tracker.result()}\n",
        "    else:\n",
        "        # Run anyway to update state\n",
        "        return_metrics = {}\n",
        "    # Updates stateful loss metrics.\n",
        "    self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)\n",
        "    self.compiled_metrics.update_state(y, y_pred['logits'], sample_weight)\n",
        "    # Collect metrics to return\n",
        "    for metric in self.metrics:\n",
        "        result = metric.result()\n",
        "        if isinstance(result, dict):\n",
        "            return_metrics.update(result)\n",
        "        else:\n",
        "            return_metrics[metric.name] = result\n",
        "    # These next two lines are also not in the base method - they correct the displayed metrics\n",
        "    # when we're using a dummy loss, to avoid a bogus \"loss_loss\" value being shown.\n",
        "    if \"loss\" in return_metrics and \"loss_loss\" in return_metrics:\n",
        "        del return_metrics[\"loss_loss\"]\n",
        "    return return_metrics\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62nOJOL9LluQ"
      },
      "source": [
        "import functools\n",
        "model.train_step = functools.partial(train_step, model)\n",
        "model.test_step = functools.partial(test_step, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFe9Y6NMmHTF"
      },
      "source": [
        "## Define an class accuracy metric\n",
        "\n",
        "Save the model weights that achieve the highest accuracy on the test set. Used as a form of regularization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WhaWBaVLI0x"
      },
      "source": [
        "def _accuracy(y_true, y_pred):\n",
        "    return tf.keras.metrics.sparse_categorical_accuracy(y_true[:, 0], y_pred[:, 0])\n",
        "\n",
        "class ClassificationAccuracy(tf.keras.metrics.MeanMetricWrapper):\n",
        "  def __init__(self, name='accuracy', **kwargs):\n",
        "    super().__init__(_accuracy, name=name, **kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXCstMzzmbpZ"
      },
      "source": [
        "## Model compile\n",
        "\n",
        "- sets up training hyperparameters (learning rate)\n",
        "- Unwrapping the `model.loss` dictionary is done so that `save_weights` works correctly. Otherwise `save_weights` throws an exception that a trackable has been modified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEag2tNGJmV4",
        "outputId": "03e07ef2-2ceb-4068-e4eb-8abeba7795bc"
      },
      "source": [
        "epochs = 50\n",
        "batch_size = 32\n",
        "init_lr = 1e-5\n",
        "\n",
        "steps_per_epoch = 1406\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = num_train_steps // 10\n",
        "\n",
        "with strategy.scope():\n",
        "\n",
        "    optimizer = optimization.create_optimizer(\n",
        "        init_lr=init_lr,\n",
        "        num_train_steps=num_train_steps,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        optimizer_type='adamw')\n",
        "\n",
        "    model.compile(optimizer=optimizer, metrics=[ClassificationAccuracy()])\n",
        "    model.loss = dict(model.loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:using Adamw optimizer\n",
            "INFO:absl:gradient_clip_norm=1.000000\n",
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! Please ensure your labels are passed as the 'labels' key of the input dict so that they are accessible to the model during the forward pass. To disable this behaviour, please pass a loss argument, or explicitly pass loss=None if you do not want your model to compute a loss.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjPocYVrnWoW"
      },
      "source": [
        "## Train\n",
        "\n",
        "- The last batch with 8 examples, rather than 32, generates a NaN loss on TPU (but not on CPU). Use only the full batches.\n",
        "- Use only a subset of the validation set since in order to save on computation costs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnVHvq17Jsc0",
        "outputId": "300da30f-9332-4044-a043-8fca499efe70"
      },
      "source": [
        "checkpoint_filepath = f'gs://{GCS_BUCKET}/{GCS_MODEL_DIR}/checkpoint'\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "    history = model.fit(\n",
        "                x=ds_train.take(1406),\n",
        "                validation_data=ds_valid.take(200),\n",
        "                callbacks=[model_checkpoint_callback],\n",
        "                epochs=epochs)\n",
        "\n",
        "model.save_pretrained('t5-model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 1) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 2) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 512) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None, 2) dtype=int64>]\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 1) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 2) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 512) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None, 2) dtype=int64>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   1406/Unknown - 463s 229ms/step - loss: 6.5669 - accuracy: 0.1802"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 512) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 1) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 2) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 512) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None, 2) dtype=int64>]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1406/1406 [==============================] - 506s 259ms/step - loss: 6.5669 - accuracy: 0.1802 - val_loss: 1.3878 - val_accuracy: 0.5531\n",
            "Epoch 2/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.3237 - accuracy: 0.7508 - val_loss: 0.5003 - val_accuracy: 0.7116\n",
            "Epoch 3/50\n",
            "1406/1406 [==============================] - 331s 236ms/step - loss: 0.1790 - accuracy: 0.8603 - val_loss: 0.3027 - val_accuracy: 0.8189\n",
            "Epoch 4/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.1276 - accuracy: 0.9029 - val_loss: 0.2758 - val_accuracy: 0.8389\n",
            "Epoch 5/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.1026 - accuracy: 0.9227 - val_loss: 0.2162 - val_accuracy: 0.8612\n",
            "Epoch 6/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0882 - accuracy: 0.9334 - val_loss: 0.2286 - val_accuracy: 0.8495\n",
            "Epoch 7/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0797 - accuracy: 0.9400 - val_loss: 0.2170 - val_accuracy: 0.8589\n",
            "Epoch 8/50\n",
            "1406/1406 [==============================] - 331s 235ms/step - loss: 0.0724 - accuracy: 0.9462 - val_loss: 0.2727 - val_accuracy: 0.8355\n",
            "Epoch 9/50\n",
            "1406/1406 [==============================] - 331s 236ms/step - loss: 0.0673 - accuracy: 0.9497 - val_loss: 0.2082 - val_accuracy: 0.8709\n",
            "Epoch 10/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0612 - accuracy: 0.9534 - val_loss: 0.2174 - val_accuracy: 0.8756\n",
            "Epoch 11/50\n",
            "1406/1406 [==============================] - 331s 236ms/step - loss: 0.0590 - accuracy: 0.9559 - val_loss: 0.2126 - val_accuracy: 0.8812\n",
            "Epoch 12/50\n",
            "1406/1406 [==============================] - 331s 236ms/step - loss: 0.0541 - accuracy: 0.9598 - val_loss: 0.2354 - val_accuracy: 0.8792\n",
            "Epoch 13/50\n",
            "1406/1406 [==============================] - 331s 235ms/step - loss: 0.0505 - accuracy: 0.9633 - val_loss: 0.2359 - val_accuracy: 0.8814\n",
            "Epoch 14/50\n",
            "1406/1406 [==============================] - 331s 235ms/step - loss: 0.0470 - accuracy: 0.9667 - val_loss: 0.2456 - val_accuracy: 0.8844\n",
            "Epoch 15/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0428 - accuracy: 0.9700 - val_loss: 0.2437 - val_accuracy: 0.8917\n",
            "Epoch 16/50\n",
            "1406/1406 [==============================] - 331s 236ms/step - loss: 0.0402 - accuracy: 0.9730 - val_loss: 0.2693 - val_accuracy: 0.8897\n",
            "Epoch 17/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0374 - accuracy: 0.9743 - val_loss: 0.3448 - val_accuracy: 0.8720\n",
            "Epoch 18/50\n",
            "1406/1406 [==============================] - 334s 237ms/step - loss: 0.0344 - accuracy: 0.9775 - val_loss: 0.2944 - val_accuracy: 0.8861\n",
            "Epoch 19/50\n",
            "1406/1406 [==============================] - 333s 237ms/step - loss: 0.0315 - accuracy: 0.9803 - val_loss: 0.2835 - val_accuracy: 0.8933\n",
            "Epoch 20/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0295 - accuracy: 0.9811 - val_loss: 0.3008 - val_accuracy: 0.8917\n",
            "Epoch 21/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0280 - accuracy: 0.9819 - val_loss: 0.3780 - val_accuracy: 0.8761\n",
            "Epoch 22/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0242 - accuracy: 0.9854 - val_loss: 0.4318 - val_accuracy: 0.8681\n",
            "Epoch 23/50\n",
            "1406/1406 [==============================] - 331s 236ms/step - loss: 0.0238 - accuracy: 0.9858 - val_loss: 0.4168 - val_accuracy: 0.8770\n",
            "Epoch 24/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0211 - accuracy: 0.9877 - val_loss: 0.3327 - val_accuracy: 0.9000\n",
            "Epoch 25/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0210 - accuracy: 0.9868 - val_loss: 0.3730 - val_accuracy: 0.8936\n",
            "Epoch 26/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0188 - accuracy: 0.9884 - val_loss: 0.4450 - val_accuracy: 0.8792\n",
            "Epoch 27/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0182 - accuracy: 0.9895 - val_loss: 0.4096 - val_accuracy: 0.8853\n",
            "Epoch 28/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0161 - accuracy: 0.9907 - val_loss: 0.4003 - val_accuracy: 0.8925\n",
            "Epoch 29/50\n",
            "1406/1406 [==============================] - 333s 237ms/step - loss: 0.0156 - accuracy: 0.9910 - val_loss: 0.4377 - val_accuracy: 0.8883\n",
            "Epoch 30/50\n",
            "1406/1406 [==============================] - 333s 237ms/step - loss: 0.0150 - accuracy: 0.9913 - val_loss: 0.4478 - val_accuracy: 0.8942\n",
            "Epoch 31/50\n",
            "1406/1406 [==============================] - 333s 237ms/step - loss: 0.0134 - accuracy: 0.9923 - val_loss: 0.4469 - val_accuracy: 0.8909\n",
            "Epoch 32/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0129 - accuracy: 0.9926 - val_loss: 0.4467 - val_accuracy: 0.8889\n",
            "Epoch 33/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0118 - accuracy: 0.9932 - val_loss: 0.4698 - val_accuracy: 0.8917\n",
            "Epoch 34/50\n",
            "1406/1406 [==============================] - 334s 237ms/step - loss: 0.0126 - accuracy: 0.9928 - val_loss: 0.4575 - val_accuracy: 0.8931\n",
            "Epoch 35/50\n",
            "1406/1406 [==============================] - 333s 237ms/step - loss: 0.0114 - accuracy: 0.9934 - val_loss: 0.5030 - val_accuracy: 0.8867\n",
            "Epoch 36/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0113 - accuracy: 0.9940 - val_loss: 0.4758 - val_accuracy: 0.8886\n",
            "Epoch 37/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0105 - accuracy: 0.9943 - val_loss: 0.4727 - val_accuracy: 0.8931\n",
            "Epoch 38/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0108 - accuracy: 0.9944 - val_loss: 0.5004 - val_accuracy: 0.8872\n",
            "Epoch 39/50\n",
            "1406/1406 [==============================] - 333s 237ms/step - loss: 0.0102 - accuracy: 0.9943 - val_loss: 0.4517 - val_accuracy: 0.8955\n",
            "Epoch 40/50\n",
            "1406/1406 [==============================] - 334s 238ms/step - loss: 0.0093 - accuracy: 0.9949 - val_loss: 0.4231 - val_accuracy: 0.9023\n",
            "Epoch 41/50\n",
            "1406/1406 [==============================] - 333s 237ms/step - loss: 0.0083 - accuracy: 0.9953 - val_loss: 0.4651 - val_accuracy: 0.8978\n",
            "Epoch 42/50\n",
            "1406/1406 [==============================] - 333s 237ms/step - loss: 0.0083 - accuracy: 0.9956 - val_loss: 0.4741 - val_accuracy: 0.8963\n",
            "Epoch 43/50\n",
            "1406/1406 [==============================] - 333s 237ms/step - loss: 0.0091 - accuracy: 0.9949 - val_loss: 0.4334 - val_accuracy: 0.9023\n",
            "Epoch 44/50\n",
            "1406/1406 [==============================] - 333s 237ms/step - loss: 0.0086 - accuracy: 0.9954 - val_loss: 0.4432 - val_accuracy: 0.9013\n",
            "Epoch 45/50\n",
            "1406/1406 [==============================] - 333s 237ms/step - loss: 0.0079 - accuracy: 0.9955 - val_loss: 0.4426 - val_accuracy: 0.9014\n",
            "Epoch 46/50\n",
            "1406/1406 [==============================] - 335s 238ms/step - loss: 0.0085 - accuracy: 0.9953 - val_loss: 0.4495 - val_accuracy: 0.9019\n",
            "Epoch 47/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0093 - accuracy: 0.9948 - val_loss: 0.3990 - val_accuracy: 0.9091\n",
            "Epoch 48/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0112 - accuracy: 0.9942 - val_loss: 0.3824 - val_accuracy: 0.9105\n",
            "Epoch 49/50\n",
            "1406/1406 [==============================] - 332s 236ms/step - loss: 0.0119 - accuracy: 0.9937 - val_loss: 0.3114 - val_accuracy: 0.9220\n",
            "Epoch 50/50\n",
            "1406/1406 [==============================] - 333s 237ms/step - loss: 0.0247 - accuracy: 0.9881 - val_loss: 0.2417 - val_accuracy: 0.9367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep3bp6OvMR9x",
        "outputId": "2a6bfd49-197e-44a6-cd8d-3d9f2c64f919"
      },
      "source": [
        "!gsutil rsync t5-model gs://$GCS_BUCKET/$GCS_MODEL_DIR/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building synchronization state...\n",
            "Starting synchronization...\n",
            "Copying file://t5-model/config.json [Content-Type=application/json]...\n",
            "Copying file://t5-model/tf_model.h5 [Content-Type=application/octet-stream]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "- [2 files][850.8 MiB/850.8 MiB]                                                \n",
            "Operation completed over 2 objects/850.8 MiB.                                    \n"
          ]
        }
      ]
    }
  ]
}